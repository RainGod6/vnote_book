# 02-时间复杂度


一般来说，一个算法执行所消耗的时间从理论上是算不出来的，只有通过上机运行才能测试出来。当然，我们也没必要知道一个算法它具体执行的时间是多少，而我们由知道，一个算法花费的时间与算法中语句执行的次数是成正比的。哪个算法语句执行的次数多，它花费的时间就多。


案例：执行次数

```
def test(n):
    count = 0
    for i in range(count,n):
        for j in range(count,n):
            count += 1
    for k in range(0,2*n):
        count += 1
    icount = 10
    while icount>0:
        count+=1
        icount-=1

```

从上面的示例我们可以得到执行次数为：f(n)=n^2+2*n+10

对于算法进行特别具体的细致分析虽然很好，但是实践中的实际价值有限。对于算法最重要的是数量级和趋势，这些是分析算法主要的部分。而计量算法基本操作数量的规模函数中那些常量因子可以忽略不计。


时间复杂度实际上就是一个函数，该函数计算的是执行基本操作的次数。一个算法语句总的执行次数关于问题规模N的某个函数，记为分f(N)，N称为问题的规模。语句总的执行次数，记为T(N),当N不断变化时，T(N)也在变化，算法的执行次数的增长速率和f(N)的增长速率相同。则T(N)=O(f(N)),称O(f(N))为时间复杂度的O渐进表示法。也叫大O计法。



分析算法时，存在几种可能的考虑：

算法完成工作最少需要多少基本操作，即最优时间复杂度
算法完成工作最多需要多少基本操作，即最坏时间复杂度
算法完成工作平均需要多少基本操作，即平均时间复杂度

对于最优时间复杂度，其价值不大，因为它没有提供什么有用信息，其反映的只是最乐观最理想的情况，没有参考价值。

对于最坏时间复杂度，是对算法的一个全面评价，因此它完整全面的反映了这个算法的性质。但另一方面，这种衡量并没有保证，不是每个计算都能在这个基本操作内完成，而且对于平均情况的计算，也会因为应用算法的实例分布可能并不均匀而难以计算。


时间复杂度的几条基本计算规则：

- 基本操作：即只有常数项，认为其时间复杂度为O(1)
- 顺序结构：时间复杂度按加法进行计算
- 循环结构：时间复杂度按乘法进行计算
- 分支结构：时间复杂度取最大值
- 判断一个算法的效率时，往往只需要关注操作数量的最高次项，其它次要项和常数项可以忽略
- 在没有特殊说明时，我们所分析的算法的时间复杂度都是指最坏时间复杂度



**常见时间复杂度**

| 执行次数函数举例 |    阶    | 非正式术语 |
| -------------- | -------- | --------- |
| 12             | O(1)     | 常数阶    |
| 2n+3           | O(n)     | 线性阶    |
| 3n2+2n+1       | O(n2)    | 平方阶    |
| 5log2n+20      | O(logn)  | 对数阶    |
| 2n+3nlog2n+19 | O(nlogn) | nlogn阶   |
| 6n3+2n2+3n+4  | O(n3)    | 立方阶    |
| 2^n            | O(2^n)   | 指数阶          |


注意，经常将log2n(以2为底的对数) 简写成logn


**常见时间复杂度之间的关系**

所消耗的时间从小到大：

O(1) < O(logn) < O(n)  < O(nlogn) < O(n2) < O(n3) < O(2^n) < O(n!) < O(n^n)




